{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize chromedriver\n",
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "nasa_url = 'https://mars.nasa.gov/news/'\n",
    "browser.visit(nasa_url)\n",
    "nasa_html = browser.html\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = BeautifulSoup(nasa_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What Two Planetary Siblings Can Teach Us About Life\n",
      "In studying Mars, NASA's InSight will reveal what makes one planet more or less suitable for life than another.\n"
     ]
    }
   ],
   "source": [
    "# Collect the latest News Title and Paragraph Text.\n",
    "latest_news_title = soup.find('div', class_='content_title').text\n",
    "latest_news_p = soup.find('div', class_='article_teaser_body').text\n",
    "                   \n",
    "print(latest_news_title)\n",
    "print(latest_news_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the text to variables that you can reference later.\n",
    "news_title = \"NASA to Host Media Call on Next Mars Landing Site\"\n",
    "\n",
    "news_p = \"NASA will host a media teleconference at 9 a.m. PST (noon EST) Monday, Nov. 19, to provide details about the Mars 2020 rover’s landing site on the Red Planet.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "jpl_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "browser.visit(jpl_url)\n",
    "browser.click_link_by_partial_text('FULL IMAGE')\n",
    "expand = browser.find_by_css('a.fancybox-expand')\n",
    "jpl_html = browser.html\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = BeautifulSoup(jpl_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA19323_ip.jpg\n"
     ]
    }
   ],
   "source": [
    "# Use splinter to navigate the site and find the image url for the current Featured Mars Image\n",
    "image = soup.find('img', class_='fancybox-image')['src']\n",
    "image_path = f'https://www.jpl.nasa.gov{image}'\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the url string to a variable called featured_image_url.\n",
    "featured_image_url = 'https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA19323_ip.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "weather_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "browser.visit(weather_url)\n",
    "weather_html = browser.html\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = BeautifulSoup(weather_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sol 2230 (2018-11-14), high -5C/23F, low -72C/-97F, pressure at 8.59 hPa, daylight 06:22-18:39'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape the latest Mars weather tweet from the Mars weather twitter account.\n",
    "tweets = soup.find('ol', class_='stream-items')\n",
    "weather = tweets.find('p', class_=\"tweet-text\").text\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tweet text for the weather report as a variable called mars_weather.\n",
    "mars_weather = 'Sol 2230 (2018-11-14), high -5C/23F, low -72C/-97F, pressure at 8.59 hPa, daylight 06:22-18:39'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "facts_url = 'https://space-facts.com/mars/'\n",
    "browser.visit(facts_url)\n",
    "facts_html = browser.html\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = BeautifulSoup(facts_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Equatorial Diameter:</td>\n",
       "      <td>6,792 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polar Diameter:</td>\n",
       "      <td>6,752 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mass:</td>\n",
       "      <td>6.42 x 10^23 kg (10.7% Earth)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moons:</td>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orbit Distance:</td>\n",
       "      <td>227,943,824 km (1.52 AU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Orbit Period:</td>\n",
       "      <td>687 days (1.9 years)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Surface Temperature:</td>\n",
       "      <td>-153 to 20 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>First Record:</td>\n",
       "      <td>2nd millennium BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Recorded By:</td>\n",
       "      <td>Egyptian astronomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Description                          Value\n",
       "0  Equatorial Diameter:                       6,792 km\n",
       "1       Polar Diameter:                       6,752 km\n",
       "2                 Mass:  6.42 x 10^23 kg (10.7% Earth)\n",
       "3                Moons:            2 (Phobos & Deimos)\n",
       "4       Orbit Distance:       227,943,824 km (1.52 AU)\n",
       "5         Orbit Period:           687 days (1.9 years)\n",
       "6  Surface Temperature:                  -153 to 20 °C\n",
       "7         First Record:              2nd millennium BC\n",
       "8          Recorded By:           Egyptian astronomers"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Pandas to scrape the table containing facts about the planet from the Mars Facts webpage.\n",
    "mars_table = soup.find('table', class_='tablepress tablepress-id-mars')\n",
    "column_1 = mars_table.find_all('td', class_='column-1')\n",
    "column_2 = mars_table.find_all('td', class_='column-2')\n",
    "\n",
    "# Initialize lists to be appended\n",
    "descriptions = []\n",
    "values = []\n",
    "\n",
    "# Append each fact to the relevant list.\n",
    "for row in column_1:\n",
    "    description = row.text.strip()\n",
    "    descriptions.append(description)\n",
    "    \n",
    "for row in column_2:\n",
    "    value = row.text.strip()\n",
    "    values.append(value)\n",
    "\n",
    "# Convert to DataFrame\n",
    "facts_df = pd.DataFrame({\n",
    "    \"Description\":descriptions,\n",
    "    \"Value\":values\n",
    "    })\n",
    "\n",
    "# Use Pandas to convert the data to a HTML table string.\n",
    "facts_html = facts_df.to_html(index=False)\n",
    "\n",
    "facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cerberus Hemisphere \n",
      "https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg\n",
      "Schiaparelli Hemisphere \n",
      "https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg\n",
      "Syrtis Major Hemisphere \n",
      "https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg\n",
      "Valles Marineris Hemisphere \n",
      "https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg\n"
     ]
    }
   ],
   "source": [
    "# URL of page to be scraped\n",
    "hemispheres_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "\n",
    "# Initialize list to be appended\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# Loop through each hemisphere link\n",
    "for i in range (1,9,2):\n",
    "    \n",
    "    # Initialize dictionary\n",
    "    hemisphere_dict = {}\n",
    "    \n",
    "    # Visit the USGS Astrogeology site to obtain high resolution images for each of Mar's hemispheres.\n",
    "    browser.visit(hemispheres_url)\n",
    "    hemispheres_html = browser.html\n",
    "    soup = BeautifulSoup(hemispheres_html, 'html.parser')\n",
    "    \n",
    "    # Click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "    # Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name.\n",
    "    hemisphere_name_links = soup.find_all('a', class_='product-item')\n",
    "    hemisphere_name = hemisphere_name_links[i].text.strip('Enhanced')\n",
    "    \n",
    "    hemisphere_detail_links = browser.find_by_css('a.product-item')\n",
    "    hemisphere_detail_links[i].click()\n",
    "    browser.find_link_by_text('Sample').first.click()\n",
    "    browser.windows.current = browser.windows[-1]\n",
    "    \n",
    "    hemisphere_image_html = browser.html\n",
    "    browser.windows.current = browser.windows[0]\n",
    "    browser.windows[-1].close()\n",
    "    \n",
    "    hemisphere_image_soup = BeautifulSoup(hemisphere_image_html, 'html.parser')\n",
    "    hemisphere_image_path = hemisphere_image_soup.find('img')['src']\n",
    "    \n",
    "    # Use a Python dictionary to store the data using the keys img_url and title.\n",
    "    print(hemisphere_name)\n",
    "    hemisphere_dict['title'] = hemisphere_name.strip()\n",
    "    \n",
    "    print(hemisphere_image_path)\n",
    "    hemisphere_dict['img_url'] = hemisphere_image_path\n",
    "    \n",
    "    # Append the dictionary with the image url string and the hemisphere title to a list.\n",
    "    hemisphere_image_urls.append(hemisphere_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'},\n",
       " {'title': 'Schiaparelli Hemisphere',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'},\n",
       " {'title': 'Syrtis Major Hemisphere',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'},\n",
       " {'title': 'Valles Marineris Hemisphere',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hemisphere_image_urls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
